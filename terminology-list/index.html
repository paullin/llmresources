<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>术语表 - llmresources</title><meta name="description" content="本文所列术语及其解释来源于李宏毅老师系列视频《生成式 AI》的课程内容。如果想进一步学习，可通过 Wikipedia 等渠道获取更详细的解释。"><meta name="generator" content="Publii Open-Source CMS for Static Site"><script type="text/javascript" async src="https://www.googletagmanager.com/gtag/js?id=G-59DLRE5LPM"></script><script type="text/javascript">window.dataLayer = window.dataLayer || [];
				  function gtag(){dataLayer.push(arguments);}
				  gtag('js', new Date());
				  gtag('config', 'G-59DLRE5LPM' );</script><link rel="stylesheet" href="https://llmresources.org/media/plugins/syntaxHighlighter/prism-black.css"><link rel="stylesheet" href="https://llmresources.org/media/plugins/syntaxHighlighter/prism-inline-color.css"><link rel="canonical" href="https://llmresources.org/terminology-list/"><link rel="alternate" type="application/atom+xml" href="https://llmresources.org/feed.xml" title="llmresources - RSS"><link rel="alternate" type="application/json" href="https://llmresources.org/feed.json" title="llmresources - JSON"><meta property="og:title" content="术语表"><meta property="og:image" content="https://llmresources.org/media/website/logo-2.png"><meta property="og:image:width" content="1536"><meta property="og:image:height" content="512"><meta property="og:site_name" content="一站式大模型资讯、工具、教程大全 - llmresources"><meta property="og:description" content="本文所列术语及其解释来源于李宏毅老师系列视频《生成式 AI》的课程内容。如果想进一步学习，可通过 Wikipedia 等渠道获取更详细的解释。"><meta property="og:url" content="https://llmresources.org/terminology-list/"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@deepnotes_org"><meta name="twitter:title" content="术语表"><meta name="twitter:description" content="本文所列术语及其解释来源于李宏毅老师系列视频《生成式 AI》的课程内容。如果想进一步学习，可通过 Wikipedia 等渠道获取更详细的解释。"><meta name="twitter:image" content="https://llmresources.org/media/website/logo-2.png"><link rel="shortcut icon" href="https://llmresources.org/media/website/favicon-2.ico" type="image/x-icon"><link rel="stylesheet" href="https://llmresources.org/assets/css/fontawesome-all.min.css?v=85514f933f9e0b82460af63f1a403fa5"><link rel="stylesheet" href="https://llmresources.org/assets/css/style.css?v=798aec0330d3fa79b38fe94ce9db2276"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://llmresources.org/terminology-list/"},"headline":"术语表","datePublished":"2025-04-17T10:33+08:00","dateModified":"2025-04-17T11:01+08:00","image":{"@type":"ImageObject","url":"https://llmresources.org/media/website/logo.png","height":512,"width":1536},"description":"本文所列术语及其解释来源于李宏毅老师系列视频《生成式 AI》的课程内容。如果想进一步学习，可通过 Wikipedia 等渠道获取更详细的解释。","author":{"@type":"Person","name":"Paul Lin","url":"https://llmresources.org/authors/paul-lin/"},"publisher":{"@type":"Organization","name":"Paul Lin","logo":{"@type":"ImageObject","url":"https://llmresources.org/media/website/logo.png","height":512,"width":1536}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript><style>.extlink::after {
				background-color: currentColor;
				content: "";
				display: inline-block;
				height: 16px;
				margin-left: 5px;
				position: relative;
				top: 0px;
				width: 16px;
			}
		
					.extlink.extlink-icon-1::after {
						mask-image: url("data:image/svg+xml;utf8,<svg viewBox='0 0 24 24' fill='none' stroke='%23000000' stroke-width='2' stroke-linecap='round' stroke-linejoin='round' xmlns='http://www.w3.org/2000/svg'><path d='M15 3h6v6'/><path d='M10 14 21 3'/><path d='M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6'/></svg>");
						mask-repeat: no-repeat;
						mask-size: contain;
					}</style></head><body class="is-preload"><div id="wrapper"><div id="main"><div class="inner"><header id="header"><a class="logo logo-image" href="https://llmresources.org/"><img src="https://llmresources.org/media/website/logo.png" alt="llmresources" width="1536" height="512"></a><ul class="icons"><li><a href="https://x.com/deepnotes_org" class="icon brands fa-x-twitter"><span class="label">Twitter</span></a></li></ul></header><article class="post"><header class="main post__header"><time datetime="2025-04-17T10:33" class="post__date">2025-04-17 10:33</time><h1>术语表</h1></header><div class="post__inner post__entry"><figure class="post__image post__image--center"><img loading="lazy" src="https://llmresources.org/media/posts/16/glossary.jpg" height="5000" width="8000" alt="terminology-list | 术语表" sizes="(max-width: 48em) 100vw, 768px" srcset="https://llmresources.org/media/posts/16/responsive/glossary-xs.webp 300w, https://llmresources.org/media/posts/16/responsive/glossary-sm.webp 480w, https://llmresources.org/media/posts/16/responsive/glossary-md.webp 768w"><figcaption>图片来源：freepik.com</figcaption></figure><p><strong>说明</strong></p><p>本文所列术语及其解释来源于李宏毅老师系列视频《<a href="https://llmresources.org/tags/introduction-gen-ai/" target="_blank">生成式 AI</a>》的课程内容。如果想进一步学习，可通过 Wikipedia 等渠道获取更详细的解释。</p><h2 id="qren-gong-zhi-nengartificial-intelligence-ai">Q：人工智能（Artificial Intelligence, AI）</h2><p>A：人工智能的目标是让机器展现“智慧”，它致力于使机器具备类似人类的智能行为，能够完成诸如学习、推理、解决问题、理解自然语言、识别图像等复杂任务，通过模拟和扩展人类智能的方式，让机器在各种领域发挥作用，为人类生活和工作提供便利与支持。<br></p><h2 id="qsheng-cheng-shi-ren-gong-zhi-neng-generative-ai">Q：生成式人工智能 (Generative AI)</h2><p>A：生成式人工智能是让机器产生复杂有结构物件的人工智能技术，这些物件包括文章、影像、语音等。其需要从近乎无穷的可能组合中找出合适的结果，比如创作一篇特定主题的文章、生成一幅特定场景的图片等，今日多以深度学习达成。<br></p><h2 id="qji-qi-xue-ximachine-learning">Q：机器学习（Machine Learning）</h2><p>A：机器学习是机器自动从资料中寻找一个函式的方法。在这个过程中，机器通过对大量数据的学习，自动调整模型的参数，以达到对数据的准确拟合和对未知数据的有效预测。就像通过已知的输入输出数据，让机器自动找出函数中的参数值 ，从而能够处理新的输入数据并给出合理输出。<br></p><h2 id="qshen-du-xue-xideep-learning">Q：深度学习（Deep Learning）</h2><p>A：深度学习是一种机器学习技术，它基于具有很多层的神经网络。这些神经网络可以自动从大量数据中学习复杂的模式和特征表示。通过构建深度的网络结构，深度学习能够处理图像、语音、文本等复杂数据，在图像识别、语音识别、自然语言处理等领域取得了显著成果。<br></p><h2 id="qlei-shen-jing-wang-luoneural-network">Q：类神经网络（Neural Network）</h2><p>A：类神经网络是一种模拟人类大脑神经元结构和功能的计算模型，由大量相互连接的节点（神经元）和边组成。这些节点按照层次结构组织，包括输入层、隐藏层和输出层。它通过对数据的学习，调整节点之间连接的权重，从而实现对数据的分类、预测等任务，是深度学习中常用的模型架构。<br></p><h2 id="qmo-xingmodel">Q：模型（Model）</h2><p>A：在人工智能领域，模型是一种数学或计算的表示形式，它基于数据和算法构建，用于模拟和预测现实世界中的现象或任务。模型包含一系列参数，通过对训练数据的学习来调整这些参数，以实现对输入数据的准确处理和输出，比如用于识别猫和狗的模型、生成文章的语言模型等。<br></p><h2 id="qcan-shuparameter">Q：参数（Parameter）</h2><p>A：参数是模型中的可调整变量，它们决定了模型的具体行为和功能。不同的参数值会导致模型对相同输入产生不同的输出。在机器学习和深度学习中，模型训练的过程就是寻找最优参数值的过程，以使得模型在处理任务时达到最佳性能，如线性函数$y = ax + b$中的$a$和$b$就是参数。<br></p><h2 id="qxun-liantraininglearning">Q：训练（Training，Learning）</h2><p>A：训练是机器学习和深度学习中的关键环节，指让模型通过对大量训练数据的学习，不断调整自身参数，以提高对数据模式的理解和任务处理能力的过程。在训练过程中，模型会根据数据的特征和标签信息，利用特定的算法来优化参数，使得模型的输出结果尽可能接近真实值，从而提升模型性能。<br></p><h2 id="qce-shitestinginference">Q：测试（Testing，Inference）</h2><p>A：测试是在模型训练完成后，使用一组未参与训练的数据对模型进行评估的过程，也叫推理。通过测试，可以了解模型对新数据的适应能力和处理准确性，判断模型是否能够泛化到不同的数据样本上。在测试时，模型根据输入数据，利用已训练好的参数进行计算，得出输出结果，以检验模型的性能和效果。<br></p><h2 id="qfen-leiclassification">Q：分类（Classification）</h2><p>A：分类是一种常见的机器学习任务，其目的是将输入数据划分到预先定义好的不同类别中。模型会根据输入数据的特征，学习到不同类别之间的差异，从而对新的输入数据进行判断和归类。例如垃圾邮件侦测、猫狗分类器等应用，就是通过分类模型将数据准确地分到相应类别中。<br></p><h2 id="qhui-guiregression">Q：回归（Regression）</h2><p>A：回归是机器学习中的一种预测任务，主要用于预测连续型的数值输出。与分类任务不同，回归模型的目标是找到输入变量和输出变量之间的关系，通常用一个数学函数来表示。通过对训练数据的学习，模型可以预测出与输入数据对应的连续数值结果，比如预测房价、股票价格走势等。<br></p><h2 id="qyu-yan-mo-xinglanguage-model">Q：语言模型（Language Model）</h2><p>A：语言模型是一种基于机器学习或深度学习技术构建的模型，用于处理自然语言任务。它可以根据给定的文本序列预测下一个可能出现的单词或短语，从而生成连贯的文本内容。语言模型通过学习大量文本数据中的语言模式和规律，具备理解和生成自然语言的能力，像ChatGPT就是一种语言模型。<br></p><h2 id="qsheng-cheng-ce-luegeneration-strategy">Q：生成策略（Generation Strategy）</h2><p>A：生成策略是指生成式人工智能在生成复杂有结构物件时所采用的方法和规则。不同的生成任务和模型会使用不同的生成策略，例如自回归生成就是一种常见的生成策略，它依照某种固定顺序依序生成较小的单位（如文字、像素等），逐步构建出完整的复杂物件。<br></p><h2 id="qzi-hui-gui-sheng-chengautoregressive-generation">Q：自回归生成（Autoregressive Generation）</h2><p>A：自回归生成是生成式人工智能中的一种生成策略，它按照一定顺序，根据已生成的部分来预测并生成下一个元素。在文本生成中，会根据前文已生成的单词预测下一个单词；在图像生成中，则根据已生成的像素预测下一个像素。通过不断重复这个过程，逐步生成完整的文章、图像等复杂有结构的物件。<br></p><h2 id="qtransformer">Q：Transformer</h2><p>A：Transformer是一种类神经网络架构，在自然语言处理和其他领域有着广泛应用。它采用了注意力机制，能够有效处理输入序列中不同位置元素之间的关系，捕捉长序列中的依赖信息。相比传统的循环神经网络和卷积神经网络，Transformer在处理长文本、提高模型并行计算能力等方面具有优势，许多先进的语言模型如ChatGPT都基于Transformer架构。&nbsp;</p></div><footer class="post__inner post__footer"><p class="post__last-updated">This article was updated on 2025-04-17 11:01</p><div class="post__share"><h3>Share post:</h3><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fllmresources.org%2Fterminology-list%2F" class="js-share icon brands fa-facebook" rel="nofollow noopener noreferrer"><span class="label">Facebook</span> </a><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fllmresources.org%2Fterminology-list%2F&amp;via=%40deepnotes_org&amp;text=%E6%9C%AF%E8%AF%AD%E8%A1%A8" class="js-share icon brands fa-x-twitter" rel="nofollow noopener noreferrer"><span class="label">Twitter</span> </a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fllmresources.org%2Fterminology-list%2F" class="js-share icon brands fa-linkedin" rel="nofollow noopener noreferrer"><span class="label">LinkedIn</span> </a><a href="https://api.whatsapp.com/send?text=%E6%9C%AF%E8%AF%AD%E8%A1%A8 https%3A%2F%2Fllmresources.org%2Fterminology-list%2F" class="js-share icon brands fa-whatsapp" rel="nofollow noopener noreferrer"><span class="label">WhatsApp</span></a></div><div class="post__tag"><ul><li><strong>Tagged in:</strong></li><li><a href="https://llmresources.org/tags/terminology/">术语表</a></li></ul></div><div class="post__bio"><img src="https://llmresources.org/media/website/Gan-Nan.png" loading="lazy" height="768" width="735" alt="Paul Lin"><div><h3><a href="https://llmresources.org/authors/paul-lin/" class="invert" rel="author">Paul Lin</a></h3><p>AI 独立开发者 / 野生产品经理 / 旅游 / 摄影。</p></div></div></footer></article><div class="comments-area"><div class="post__inner"><div class="comments"><div class="comments-wrapper"><h2>Comments</h2><div id="cusdis_thread" data-host="https://cusdis.com" data-app-id="93ea2454-1da0-4086-b4b0-3723cee14ad0" data-page-id="16" data-page-url="https://llmresources.org/terminology-list/" data-page-title="术语表" data-theme="auto"></div><noscript>Please enable JS to use the comments form.</noscript><script type="text/javascript">var cusdis_element_to_check = document.getElementById('cusdis_thread');

				if ('IntersectionObserver' in window) {
					var iObserver = new IntersectionObserver(
						(entries, observer) => {
							entries.forEach(entry => {
								if (entry.intersectionRatio >= 0.1) {
									(function () {
										var d = document, s = d.createElement('script');
										s.defer = true;
										s.src = 'https://cusdis.com/js/cusdis.es.js';									
										(d.head || d.body).appendChild(s);
									})();
									observer.unobserve(entry.target);
								}
							});
						},
						{
							threshold: [0, 0.2, 0.5, 1]
						}
					);

					iObserver.observe(cusdis_element_to_check);
				} else {
					(function () {
						var d = document, s = d.createElement('script');
						s.defer = true;
						s.src = 'https://cusdis.com/js/cusdis.es.js';
						(d.head || d.body).appendChild(s);
					})();
				}</script><script type="text/javascript"></script></div></div></div></div></div></div><div id="sidebar"><div class="inner"><div id="search" class="alt"><form action="https://llmresources.org/search.html" class="search__form"><input class="search__input" type="search" name="q" placeholder="搜索..." aria-label="搜索..."></form></div><nav id="menu"><header class="major"><h2>Menu</h2></header><ul><li><a href="https://llmresources.org/" target="_self">首页</a></li><li class="has-submenu"><span aria-haspopup="true" class="opener">教程</span><ul class="submenu level-2" aria-hidden="true"><li><a href="https://llmresources.org/tags/introduction-gen-ai/" target="_blank">生成式 AI 教程</a></li><li><a href="https://llmresources.org/tags/llm-paper/" target="_blank">参考论文</a></li><li><a href="https://llmresources.org/tags/terminology/" target="_blank">术语表</a></li></ul></li><li class="has-submenu"><span aria-haspopup="true" class="opener">工具</span><ul class="submenu level-2" aria-hidden="true"><li><a href="https://llmresources.org/tags/agent-tool/" target="_blank">Agent 工具</a></li><li><a href="https://llmresources.org/tags/mcp-server/" target="_blank">MCP 服务器</a></li></ul></li><li class="has-submenu"><span aria-haspopup="true" class="opener">资讯</span><ul class="submenu level-2" aria-hidden="true"><li><a href="https://llmresources.org/tags/llm-latest/" target="_blank">大模型进展</a></li></ul></li></ul></nav><section><header class="major"><h2>Editor Pick's</h2></header><div class="mini-posts"><article><h3><a href="https://llmresources.org/genai-tutorial/">系列教程：生成式 AI 导论</a></h3><p></p><figure class="post__image post__image--center"><img loading="lazy" src="https://llmresources.org/media/posts/17/Feng-Mian-Tu.jpg" height="3335" width="5001" alt="GenAI | 生成式AI" sizes="(max-width: 48em) 100vw, 768px" srcset="https://llmresources.org/media/posts/17/responsive/Feng-Mian-Tu-xs.webp 300w, https://llmresources.org/media/posts/17/responsive/Feng-Mian-Tu-sm.webp 480w, https://llmresources.org/media/posts/17/responsive/Feng-Mian-Tu-md.webp 768w"><figcaption>图片来源：freepik.com</figcaption></figure><p>摘要：该系列来源于油管上同名热门视频《生成式 AI 导论 (2024)》的文字稿，教授者是台湾计算机科学家、国立台湾大学电机工程学系教授李宏毅。课程内容深入浅出，幽默风趣，将很多艰深晦涩的专业名词用大白话讲得明明白白。同时提供了很多参考学习的论文。实为学习 AI 的最佳入门材料。</p><p></p></article></div><ul class="actions"><li><a href="https://llmresources.org/tags/introduction-gen-ai/" class="button">More</a></li></ul></section><section><header class="major"><h2>Get in touch</h2></header><ul><li>投稿入口：deepnotes.org@gmail.com</li><li>微信好友：paullin81</li></ul><p> </p></section><footer id="footer"><p class="copyright">© Editorial 2 - All rights reserved<br>Design by: <a href="https://html5up.net" target="_blank" rel="noopener">HTML5 UP</a>, Powered by Publii</p></footer></div></div></div><script src="https://llmresources.org/assets/js/jquery.min.js?v=7c14a783dfeb3d238ccd3edd840d82ee"></script><script src="https://llmresources.org/assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="https://llmresources.org/assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="https://llmresources.org/assets/js/util.min.js?v=cbdaf7c20ac2883c77ae23acfbabd47e"></script><script src="https://llmresources.org/assets/js/main.min.js?v=08add7f6d435054ad38ec38d7cf8be40"></script><script>var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};</script><script defer="defer" src="https://llmresources.org/media/plugins/syntaxHighlighter/prism.js"></script><script defer="defer" src="https://llmresources.org/media/plugins/syntaxHighlighter/prism-line-numbers.min.js"></script><script defer="defer" src="https://llmresources.org/media/plugins/syntaxHighlighter/clipboard.min.js"></script><script defer="defer" src="https://llmresources.org/media/plugins/syntaxHighlighter/prism-copy-to-clipboard.min.js"></script><script defer="defer" src="https://llmresources.org/media/plugins/syntaxHighlighter/prism-inline-color.min.js"></script></body></html>